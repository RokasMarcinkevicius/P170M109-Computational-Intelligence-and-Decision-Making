{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fcfb6db",
   "metadata": {},
   "source": [
    "# CIDM Lab 1 — Simple Final Pipeline (Code Only)\n",
    "Minimal, correct pipeline for price prediction using **KNN, Decision Tree, Random Forest**.\n",
    "- Robust `price_type` normalization → `price_monthly`\n",
    "- Light cleaning & encoding\n",
    "- 70/15/15 split\n",
    "- Scaling numerics for KNN\n",
    "- Baseline + 3 hyperparam sets per model\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac3f8d30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T16:44:19.092418Z",
     "start_time": "2025-09-22T16:44:19.087907Z"
    }
   },
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "CSV_PATHS = [\n",
    "    \"/mnt/data/apartments_for_rent_classified_100K.csv\",\n",
    "    \"/mnt/data/apartments_for_rent_classified_10K.csv\",\n",
    "    \"apartments_for_rent_classified_100K.csv\",\n",
    "    \"apartments_for_rent_classified_10K.csv\",\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "92b8a3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T16:44:19.182423Z",
     "start_time": "2025-09-22T16:44:19.136089Z"
    }
   },
   "source": [
    "def to_monthly(price, ptype):\n",
    "    t = (str(ptype) if ptype is not None else \"\").strip().lower()\n",
    "    try:\n",
    "        p = float(price)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    if not np.isfinite(p) or p <= 0:\n",
    "        return np.nan\n",
    "    if \"week\" in t:             factor = 52/12\n",
    "    elif \"fortnight\" in t or \"biweek\" in t: factor = 26/12\n",
    "    elif \"day\" in t:            factor = 30\n",
    "    elif \"year\" in t or \"annual\" in t:      factor = 1/12\n",
    "    elif \"hour\" in t:           factor = 24*30\n",
    "    else:                       factor = 1.0  # assume monthly\n",
    "    return p * factor\n",
    "\n",
    "def load_first_available(paths):\n",
    "    for p in paths:\n",
    "        try:\n",
    "            df = pd.read_csv(p)\n",
    "            print(\"Loaded:\", p)\n",
    "            return df\n",
    "        except Exception:\n",
    "            continue\n",
    "    raise FileNotFoundError(\"Place the CSV next to this notebook or in /mnt/data/.\")\n",
    "\n",
    "df_raw = load_first_available(CSV_PATHS)\n",
    "print(\"Shape raw:\", df_raw.shape)\n",
    "df_raw.head(3)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Place the CSV next to this notebook or in /mnt/data/.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 27\u001B[39m\n\u001B[32m     24\u001B[39m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m     25\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mPlace the CSV next to this notebook or in /mnt/data/.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m df_raw = \u001B[43mload_first_available\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCSV_PATHS\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mShape raw:\u001B[39m\u001B[33m\"\u001B[39m, df_raw.shape)\n\u001B[32m     29\u001B[39m df_raw.head(\u001B[32m3\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 25\u001B[39m, in \u001B[36mload_first_available\u001B[39m\u001B[34m(paths)\u001B[39m\n\u001B[32m     23\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m     24\u001B[39m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mPlace the CSV next to this notebook or in /mnt/data/.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: Place the CSV next to this notebook or in /mnt/data/."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Normalize price to monthly and clean\n",
    "df = df_raw.copy()\n",
    "\n",
    "if \"price_monthly\" not in df.columns:\n",
    "    if \"price\" not in df.columns or \"price_type\" not in df.columns:\n",
    "        raise KeyError(\"Expected columns 'price' and 'price_type'.\")\n",
    "    df[\"price_monthly\"] = df.apply(lambda r: to_monthly(r.get(\"price\"), r.get(\"price_type\")), axis=1)\n",
    "\n",
    "# currency filter\n",
    "if \"currency\" in df.columns:\n",
    "    df = df[df[\"currency\"].astype(str).str.upper().eq(\"USD\") | df[\"currency\"].isna()]\n",
    "\n",
    "# drop invalid target\n",
    "df = df.dropna(subset=[\"price_monthly\"])\n",
    "df = df[np.isfinite(df[\"price_monthly\"]) & (df[\"price_monthly\"] > 0)]\n",
    "\n",
    "# encode binaries\n",
    "for col in [\"fee\",\"has_photo\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = (df[col].astype(str).str.lower()\n",
    "                   .map({\"yes\":1,\"no\":0,\"thumbnail\":1}).fillna(0).astype(int))\n",
    "\n",
    "# pets flags\n",
    "if \"pets_allowed\" in df.columns:\n",
    "    lower = df[\"pets_allowed\"].fillna(\"\").astype(str).str.lower()\n",
    "    df[\"pet_cat_allowed\"] = lower.str.contains(\"cat\").astype(int)\n",
    "    df[\"pet_dog_allowed\"] = lower.str.contains(\"dog\").astype(int)\n",
    "\n",
    "# coords validity\n",
    "if \"latitude\" in df.columns and \"longitude\" in df.columns:\n",
    "    lat = pd.to_numeric(df[\"latitude\"], errors=\"coerce\")\n",
    "    lon = pd.to_numeric(df[\"longitude\"], errors=\"coerce\")\n",
    "    good = lat.between(-90, 90) & lon.between(-180, 180) & ~((lat.abs()<0.1) & (lon.abs()<0.1))\n",
    "    df = df[good]\n",
    "\n",
    "# area sanity\n",
    "if \"square_feet\" in df.columns:\n",
    "    sf = pd.to_numeric(df[\"square_feet\"], errors=\"coerce\")\n",
    "    df = df[(sf.isna()) | ((sf >= 120) & (sf <= 8000))]\n",
    "\n",
    "# drop duplicate ids\n",
    "if \"id\" in df.columns:\n",
    "    df = df.drop_duplicates(subset=[\"id\"])\n",
    "\n",
    "# drop unused columns\n",
    "drop_cols = [\"id\",\"title\",\"body\",\"address\",\"amenities\",\"price_display\",\"price_type\",\"price\",\"source\"]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "# fill numeric NaNs\n",
    "for c in df.select_dtypes(include=[np.number]).columns:\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "# clip top 0.5% price outliers\n",
    "q995 = df[\"price_monthly\"].quantile(0.995)\n",
    "df = df[df[\"price_monthly\"] <= q995]\n",
    "\n",
    "print(\"Shape clean:\", df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb00e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split and scale (for KNN) ---\n",
    "y = df[\"price_monthly\"].astype(float)\n",
    "X = df.drop(columns=[\"price_monthly\"])\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1765, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_val[num_cols]   = scaler.transform(X_val[num_cols])\n",
    "X_test[num_cols]  = scaler.transform(X_test[num_cols])\n",
    "\n",
    "print(\"Splits:\", X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebc81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Eval helper ---\n",
    "def eval_model(name, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    for split, X_, y_ in [(\"Train\",X_train,y_train),\n",
    "                          (\"Val\",X_val,y_val),\n",
    "                          (\"Test\",X_test,y_test)]:\n",
    "        pred = model.predict(X_)\n",
    "        mae = mean_absolute_error(y_, pred)\n",
    "        mape = mean_absolute_percentage_error(y_, pred) * 100\n",
    "        r2 = r2_score(y_, pred)\n",
    "        print(f\"{name:<18} {split:<5} | MAE={mae:8.1f} | MAPE={mape:5.1f}% | R2={r2:6.3f}\")\n",
    "    print()\n",
    "\n",
    "# Baseline\n",
    "baseline = np.full_like(y_test, y_train.mean())\n",
    "print(\"Baseline (mean)  Test | MAE={:.1f} | MAPE={:.1f}% | R2={:.3f}\".format(\n",
    "    mean_absolute_error(y_test, baseline),\n",
    "    mean_absolute_percentage_error(y_test, baseline) * 100,\n",
    "    r2_score(y_test, baseline)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7af84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KNN ---\n",
    "for k in [3,5,10]:\n",
    "    eval_model(f\"KNN k={k}\", KNeighborsRegressor(n_neighbors=k))\n",
    "\n",
    "# --- Decision Tree ---\n",
    "for d in [5,10,None]:\n",
    "    eval_model(f\"DecisionTree d={d}\", DecisionTreeRegressor(max_depth=d, random_state=42))\n",
    "\n",
    "# --- Random Forest ---\n",
    "for n in [10,50,100]:\n",
    "    eval_model(f\"RandomForest n={n}\", RandomForestRegressor(n_estimators=n, random_state=42))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
